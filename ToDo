Wir können in CSV-Tabellen bestimmte Winkel und Positionen vorgeben
   Es wäre aber auch ganz schön,
   in die Analyse der Paare von Bildern eingreifen zu können.
   Beispiel:
   Ich sehe, dass eine Paarbeziehung vom Programm falsch erkannt wird.
   Dann möchte ich diese Paarbeziehung aus der Tabelle streichen.
   Die Tabelle könnte so aussehen:
   	Image	Angle	DX0	DY0	DX1	DY1	DX2	DY2
   Bei processOverlap wäre das kein großes Problem.
   Soll man bei processOverlapRotate eher solche:
	DX0	DY0	R0
   oder eher solche Spalten verwenden:
	DX0_0	DY0_0	DX0_1	DY0_1	DX0_2	DY0_2
   oder eher solche:
	Over0	Over1	Over2
   ?
   Der Wert in einer Over-Spalte kann sein:
      ' ' - Programm soll selber bestimmen
      'X' - Bildpaar überlappt sich
      '-' - Bildpaar überlappt sich nicht
   Variante DX DY R:
      DX DY R wären so zu verstehen:
         Bilder eines Paares mit (DX/2,DY/2) aufeinander zu bewegen
         und mit R/2 aufeinander zu drehen
      Konvertierung (Zuordnung Stamps) -> (DX, DY, R)
         Gleichungssystem lösen
      Konvertierung (DX, DY, R) -> (Zuordnung Stamps)
         Stamps drehen
   Diese Ersetzungen sind aber nicht äquivalent.
   Eigentlich bleibt nur,
      die Paarbeziehungen direkt in die Zellen zu schreiben.
      Weil es bei --finetune-rotate so viele sind, würde ich sagen,
      dass man alle Parameter in eine Zelle schreibt,
      auch wenn sie dadurch riesig wird.
      Auf diese Weise kann man aber eine einzelne Beziehung schnell wegstreichen.
   Alternative:
      In die Matrix schreiben wir nur Referenzen auf Zeilen in einer weiteren CSV-Datei
      oder in der gleichen CSV-Datei,
      aber einer abgesetzten Tabelle weiter unten.
   So könnten wir einfaches Streichen von Beziehungen kombinieren
      mit dem Speichern der Zahlenwerte,
      was erneute Berechnung vermeidet.
   Für processOverlap brauchen wir Spalten DX und DY.
   Für processOverlapRotate:
	X0A	Y0A	X0B	Y0B	...	X4A	Y4A	X4B	Y4B
   Nee, wir lassen die Dreiecksmatrix in state.csv ganz weg
   und machen eigenständige Tabelle state-overlap.csv:
	ImageA	ImageB	Relation	DX	DY
   Relation:
      ' ' - lasse Programm bestimmen, ob Bilder überlappen und wenn ja mit welchem Versatz
      '-' - lege fest, dass sich Bilder nicht überlappen
      'X' - lege fest, dass sich Bilder überlappen, aber lass Programm den Versatz bestimmen
      'F' - lege fest, dass sich Bilder überlappen und lege auch Versatz fest
            anhand der folgenden Spalten

MatchImageBorders: denkbare Verbesserungen
   Ist es sinnvoll und möglich, weniger ausgefranste Umrisse zu erhalten?
      Bestrafe auf irgendeine Weise die Entfernung von Punkten,
         wenn sie zu längeren Umrissen führt.
      Man könnte alle 256 möglichen 8er-Umgebungen
         irgendwie mit der Länge der Linien bewerten
         und das Gewicht geringer machen, je länger die Linien sind.
      Oder einfach so:
         Bestrafe die Anzahl _innerer_ Punkte,
         die nach Entfernen des Punktes
         neu in die Warteschlange aufgenommen werden müsste.
         So hält man auch die Warteschlange klein.
      Sobald ein Punkt aus Warteschlange entfernt wird,
         müssen aber die Prioritäten für alle Punkte in Umgebung angepasst werden.
      D.h. wir brauchen eine Prioritätenwarteschlange mit Suche (psqueues).
   beziehe in Differenz auch die Farbkomponenten ein
   wenn ein Punkt entfernt wird,
      passe Differenz zu Mittelwert der verbleibenden Punktwerte
      an der gleichen Stelle an

MatchImageBorders.shapeParts
   könnte statt auf Liste von Feldern
      auch auf einem dreidimensionalen Feld arbeiten

MatchImageBorders
   glätte abgeknabberte Umrisse
   optimal wäre, wenn ein Glättungsschritt das Bild um eine Bildpunktzeile
   in jeder Richtung vergrößert und dabei auch in negative Indizes hineinwächst.

MatchImageBorders
   mit Physical.Array implementieren
   benötigt wahrscheinlich Physical.scatter
      und neue ST- oder IO-basierte veränderliche Variante

MatchImageBorders
   begrenze Teil-Bilder auf Bounding-Box der gedrehten Bilder
   nutze dafür Felder mit Indexuntergrenzen, die verschieden von null sind

besseres Überlagern der Teilbilder
   Das Überblenden sollte möglichst in Bereichen
   mit wenig Information passieren.
   Da wo keine Schrift ist, sondern recht einfacher Hintergrund,
   fällt das Überblenden am wenigsten auf.
   Oder blende dort über,
   wo die Differenz zwischen den übereinander liegenden Bildern gering ist.
   Man braucht jedenfalls eine Art Gewichtsverteilung,
   und man sollte dort überblenden, wo das Gewicht am geringsten ist.
   Das ist aber eine recht anspruchsvolle mathematische Aufgabe.
   Es geht darum, ein Netz von gekrümmten Wegen zu finden,
      die die Einzelbilder beschneiden, so dass sie gekrümmte Ränder haben,
      die genau aneinanderstoßen.
   Ansatz:
      Nimm Schnittpunkte von Kanten überlappender Bilder.
      Finde zwischen diesen Schnittpunkten kürzeste Wege,
      wobei Gebiete mit großen Bildunterschieden mit hohen Kosten belegt sind.
      Verlaufen diese Wege teilweise zusammen?
      Kann man daraus ein Netz spannen?
      Man könnte den Graphen all dieser Wege
         zu einem minimal aufspannenden Baum ausdünnen.
   Anderer Ansatz:
      Berechne von jedem Schnittpunkt aus
      komplette Profile für kürzeste Entfernungen.
      Suche den Punkt, wo die Summe der kürzesten Wege minimal ist.
      Von diesem Punkt aus nimm alle kürzesten Wege zu den Schnittpunkten.
      Was kommt da heraus?
      Verlaufen dabei Wege teilweise gleich?
   Anderer Ansatz analog zu Kruskals minimal aufspannenden Baum:
      Beginne mit Gesamtgebiet überlappender Bereiche.
      Entferne aus diesem Gebiet Schritt für Schritt Punkte
      nach absteigendem Gewicht.
      Überspringe Entfernung von Punkten,
      wenn dadurch der Graph irgendwie ungünstig zerfallen würde.
      Manchmal ist es ganz gut, wenn eine Verbindung gekappt wird,
      aber manchmal auch nicht.
      Was ist das genaue Kriterium?
   Daran anküpfend:
      Knabbere überall da von den Rändern der Bilder etwas weg,
      wo mehrere Bilder übereinander liegen und das Gewicht sehr groß ist.
      Der Algorithmus endet,
      wenn an jeder Position nur noch der Bildpunkt eines Bildes zu sehen ist.
      Überlagerung:
         Nimm Silhouetten von abgeknabberten Bildern
         und glätte sie mit Gaußfilter.
         Nimm geglättete Silhouetten als Wichtung bei Überlagerung.

besserer Matching-Score
   bei "Kaltes Herz" schlägt die Erkennung der optimalen relativen Verschiebung
      zwischen Teil links oben und rechts unten fehl
   Evtl. mit Wurzel der überlappenden Fläche wichten?

automatische Erkennung von fehlerhaften Paaren:
   Wenn bei Ausgleichsproblem großer Fehler bleibt,
   dann schaue, welche Paare man bei der Ausgleichsrechnung am besten weglässt.

bisher nur JPEG unterstützt
   JuicyPixel unterstützt auch TIFF und PNG
   aber wir müssten zusätzlich RGB u.ä. erlauben

Optionen:
   --output=PATH
   --output-hard=PATH
   --output-overlap
   --output-distancemap
   --quality=PERCENT
   --scale=FACTOR
   --smooth=RADIUS
   --minimum-overlap=SIZE
   --maximum-difference=REAL
   --pad-size=SIZE
   --verbose
   --help

   --angle fix rotation angle for the next input file

Abhängigkeit von gnuplot nicht nötig

unterschiedliche horizontale und vertikale Auflösung
   für diesen Fall könnte man allgemeine lineare Abbildung ansetzen

finetune-rotate:
   statt linearer Verteilung von kleinen Fenstern
      könnte man Zufallsverteilung nehmen

   wenn kleine Fenster nahezu konstante Werte enthalten,
      dann schlägt Algorithmus evtl. fehl
      Ich sollte vielleicht Fenster mit zu geringen Helligkeitsschwankungen ignorieren.

soll man "matching" besser nur auf innerem Rechteck mit vollständig gültigen Daten berechnen?
   Wie berechnet man (flächenmäßig) größtes einbeschriebenes Iso-Rechteck?

falsche Formatschablonen in Output-Dateinamen führen zu Laufzeitfehler
   Teste Format vorher auf richtiges Format :-)

Als Sahnehäubchen könnte Programm noch selber die richtige Orientierung
   in 90°-Schritten herausfinden.

Punkte auf dem Bildrand haben Abstand null
   das kann zu Division durch null führen
   Besser pauschal eins addieren?

Wie geht man mit 0/0 um?
   Tritt an allen Stellen auf, an denen kein Bildteil zu sehen ist.
   Anscheinend macht die GPU dort automatisch Null hin.
   Müsste auch auftreten, wenn man nur nicht überlappende Bilder hat
      "Ein einziges Bild" wäre davon ein Spezialfall.


kann man bei der schnellen Fourier-Transformation ausnutzen,
   wenn nur ein Teil der Daten ungleich null ist?

Algorithmus mal mit Ausschnitten von Bildern testen

man sieht bei mpb immer noch Schlitze an den Schnittstellen
   das dürfte eigentlich dank Rotationsmaske nicht sein.
   Ich muss mir mal Rotationsmasken ausgeben lassen und überprüfen.
   Hm, die Small-Bilder sind teilweise schon gedreht und haben helle Keile am Rand.
   Das erklärt alles.

man müsste eigentlich einen Rahmen mit 1 Bildpunkt Breite abschneiden,
   weil dieser Rand schon von der konstanten Randfortsetzung beeinträchtigt wird

Umsortieren in "Bitplanes":
   die Reihenfolge der Dimensionen sollte sein:
      Z :. Kanal :. Höhe :. Breite
   Dann kann man die gleiche Rotationsroutine
      für Graustufen und für Farbbilder verwenden.
   So lässt sich ein Bild aber schlecht mit einer Maske kombinieren.
   Vielleicht sollte ich doch einen eigenen YUV-Elementtyp definieren?
   Dann brauche auch aber auch Vektorskalierung und solche Sachen.


Annahme:
   alle Bilder nahezu in der selben Orientierung
      so ist sichergestellt,
         dass (leicht) verschiedene Auflösungen
         in x- und y-Richtung nicht stören
      180°-Grad-Drehungen kann man vorher rückgängig machen
   alle Bilder gleich groß

Zwei Phasen:
   Anordnung der Bilder finden
   Bilder überlagern


Orientierung finden, 1. Ansatz:
   Bild um maximal 1 Grad in 0.01-Grad-Schritten drehen
   Von jeder Drehung horizontales und vertikales Histogramm berechnen
   Nach dem Winkel suchen, wo im Histogramm die steilsten Flanken auftreten
      Solche Flanken sollten wenigstens vom Bildrand erzeugt werden,
      oder aber von Schrift.

Orientierung finden, 2. Ansatz:
   Für jeden Punkt über mehrere Ringe mitteln (Rotationsunabhängigkeit)
   Für jeden Punkt entsteht so ein Merkmalsvektor von vielleicht 5x3 Werten
   Diese Vektoren in ein quantisiertes Gitter eintragen.
   Ist in einer Zelle nur ein Vektor, so ist der Punkt besonders markant.
   Diese Punkte sollte man in anderen Bildern suchen.
   Hat man eine Menge Punkte in den Bildern einander zugeordnet,
      so kann man Drehung und Position herausfinden.

Orientierung finden, 3. Ansatz:
   Bild in kleinen Schritten drehen
   den Benutzer die passende Drehung aussuchen lassen
   oder schauen, wann es am besten zu anderem Bild passt

Position finden:
   Mit FFT zwei Bilder falten und Position mit höchster Korrelation nehmen

Überlagern:
   Es sollten Bilder linear interpoliert werden,
      so dass es keine harten Schnittstellen gibt.
   Die richtigen Wichtungsfaktoren für jedes Bild zu finden,
      ist ganz schön knifflig.
   Idee: Führe Aufgabe auf lineare Schnitte durch die Bilder zurück.
      Beobachtung:
         Intervalle, die andere Intervalle enthalten können wir weglassen.
         D.h. aber, dass es nur die Situation
            [          ]
              [          ]
                [          ]
         geben kann.
         Bei Schnitten durch Bilder können auf einzelnen Geraden
         durchaus Intervalle komplett in anderen enthalten sein,
         und man muss die Teilintervalle trotzdem beachten.
         D.h. dass man die 2D-Aufgabe nicht auf 1D zurückführen kann,
         und weil die Anordnung nichttrivialer Intervalle
         immer die gleiche ist, lässt sich aus dem 1D-Fall auch nichts lernen.
