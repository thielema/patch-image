cabal run patch-image-llvm -- --output-overlap='/tmp/overlap-%s-%s.jpeg' --output=/tmp/collage-smooth.jpeg --output-hard=/tmp/collage-hard.jpeg data/wmb?small.jpeg

Geht Drehen schneller, wenn man es auf kleine Bild-Kacheln anwendet?
   Die Frage ist, ob das Cache-freundlicher wäre.

Option: benutze optparse-applicative
   erlaube output-overlap-Option nur, wenn kein finetune-rotate angegeben

Demonstriere Progamm an Beispielbildern:
   zerschnippelter Lorem-Ipsum-Text mit Fotos

Benutze mehrere Kerne
   sollte man immer +RTS -N - auf maximale Anzahl Prozesse setzen,
   und dann mit einer -j-Option nur einen Teil davon nutzen lassen?
   Das ginge zumindest schon mit GHC-7.4.2.
   Eine einfache Parallelisierung bestünde darin,
   die Rotations- und Überlappungsphasen hintereinander laufen zu lassen
   und die einzelnen Rotations- und Überlappungsjobs zu parallelisieren.
   Sobald man die ersten zwei Bilder rotiert hat,
   kann man sie aber in die Überlappungsroutine stecken.
   Nötig ist das aber nicht.
   Es reicht auch, die Rotationsjobs erst alle parallelisiert abzuarbeiten
   und dann die Überlappungsjobs bereits halb parallel mitabzuarbeiten.
   Sinnvoll wäre es, die Überlappungsjobs so anzuordnen,
   dass erst die Bilder mit den kleinen Nummern drankommen,
   denn deren Rotationsbestimmungen sind am ehesten durch.
   Die Unterteilung des Programmes in Phasen
   ist dann vielleicht nicht mehr so sinnvoll,

benutze NonEmpty für Liste von Bildern

move to accelerate-1.0

State.Rotated:
   Wir testen zwar überall auf Konsistenz,
   aber der Csv.Parser zeigt am Ende meistens nur EndOfInput als Meldung. :-(

leastSquaresSelected:
   würde auch eine schöne Hilfsfunktion für ein LAPACK-Utility-Paket abgeben

layoutFromPairDisplacements:
   NonEmptyMixed.sliceVertical: könnte das Zerlegen typsicher machen

layoutFromPairDisplacements, alternative Implementierung:
   setze Matrixmultiplikation so um, wie sie im Kommentar steht,
   also als Beziehung zwischen zwei Bildern.
   Weil das von Anordnung des Bildpaares abhängt,
   schreibe immer beide Richtungen in Gleichungssystem.
   Das haut aber auch nicht hin,
   weil man in umgekehrter Richtung Rotation und Verschiebung vertauschen müsste.
   Oder man arbeitet von beiden Bilden zu einem gemeinsamen Mittelpunkt
      auf halber Strecke mit halber Drehung.
   Damit kann man nur Drehungen zueinander bestimmen.
   Das könnten wir aber für Paartabelle nutzen.

LibreOffice ist nicht gut im Lesen von CSV mit englischen Zahlen
   Können das alternative Tabellenkalkulationen besser?
   gnumeric, calligrasheets, pyspread

Is correlation the right operation for matching shifted images?
   Could we compute norms of image differences instead?

correlatePadded:
   wrap array, such that negative offsets are at negative indices
   shrink to the real size

MatchImageBorders: denkbare Verbesserungen
   Ist es sinnvoll und möglich, weniger ausgefranste Umrisse zu erhalten?
      Bestrafe auf irgendeine Weise die Entfernung von Punkten,
         wenn sie zu längeren Umrissen führt.
      Man könnte alle 256 möglichen 8er-Umgebungen
         irgendwie mit der Länge der Linien bewerten
         und das Gewicht geringer machen, je länger die Linien sind.
      Oder einfach so:
         Bestrafe die Anzahl _innerer_ Punkte,
         die nach Entfernen des Punktes
         neu in die Warteschlange aufgenommen werden müsste.
         So hält man auch die Warteschlange klein.
      Sobald ein Punkt aus Warteschlange entfernt wird,
         müssen aber die Prioritäten für alle Punkte in Umgebung angepasst werden.
      D.h. wir brauchen eine Prioritätenwarteschlange mit Suche (psqueues).
   beziehe in Differenz auch die Farbkomponenten ein
   wenn ein Punkt entfernt wird,
      passe Differenz zu Mittelwert der verbleibenden Punktwerte
      an der gleichen Stelle an

MatchImageBorders.shapeParts
   könnte statt auf Liste von Feldern
      auch auf einem dreidimensionalen Feld arbeiten

MatchImageBorders
   glätte abgeknabberte Umrisse
   optimal wäre, wenn ein Glättungsschritt das Bild um eine Bildpunktzeile
   in jeder Richtung vergrößert und dabei auch in negative Indizes hineinwächst.

MatchImageBorders
   mit Physical.Array implementieren
   benötigt wahrscheinlich Physical.scatter
      und neue ST- oder IO-basierte veränderliche Variante

MatchImageBorders
   begrenze Teil-Bilder auf Bounding-Box der gedrehten Bilder
   nutze dafür Felder mit Indexuntergrenzen, die verschieden von null sind

besseres Überlagern der Teilbilder
   Das Überblenden sollte möglichst in Bereichen
   mit wenig Information passieren.
   Da wo keine Schrift ist, sondern recht einfacher Hintergrund,
   fällt das Überblenden am wenigsten auf.
   Oder blende dort über,
   wo die Differenz zwischen den übereinander liegenden Bildern gering ist.
   Man braucht jedenfalls eine Art Gewichtsverteilung,
   und man sollte dort überblenden, wo das Gewicht am geringsten ist.
   Das ist aber eine recht anspruchsvolle mathematische Aufgabe.
   Es geht darum, ein Netz von gekrümmten Wegen zu finden,
      die die Einzelbilder beschneiden, so dass sie gekrümmte Ränder haben,
      die genau aneinanderstoßen.
   Ansatz:
      Nimm Schnittpunkte von Kanten überlappender Bilder.
      Finde zwischen diesen Schnittpunkten kürzeste Wege,
      wobei Gebiete mit großen Bildunterschieden mit hohen Kosten belegt sind.
      Verlaufen diese Wege teilweise zusammen?
      Kann man daraus ein Netz spannen?
      Man könnte den Graphen all dieser Wege
         zu einem minimal aufspannenden Baum ausdünnen.
   Anderer Ansatz:
      Berechne von jedem Schnittpunkt aus
      komplette Profile für kürzeste Entfernungen.
      Suche den Punkt, wo die Summe der kürzesten Wege minimal ist.
      Von diesem Punkt aus nimm alle kürzesten Wege zu den Schnittpunkten.
      Was kommt da heraus?
      Verlaufen dabei Wege teilweise gleich?
   Anderer Ansatz analog zu Kruskals minimal aufspannenden Baum:
      Beginne mit Gesamtgebiet überlappender Bereiche.
      Entferne aus diesem Gebiet Schritt für Schritt Punkte
      nach absteigendem Gewicht.
      Überspringe Entfernung von Punkten,
      wenn dadurch der Graph irgendwie ungünstig zerfallen würde.
      Manchmal ist es ganz gut, wenn eine Verbindung gekappt wird,
      aber manchmal auch nicht.
      Was ist das genaue Kriterium?
   Daran anküpfend:
      Knabbere überall da von den Rändern der Bilder etwas weg,
      wo mehrere Bilder übereinander liegen und das Gewicht sehr groß ist.
      Der Algorithmus endet,
      wenn an jeder Position nur noch der Bildpunkt eines Bildes zu sehen ist.
      Überlagerung:
         Nimm Silhouetten von abgeknabberten Bildern
         und glätte sie mit Gaußfilter.
         Nimm geglättete Silhouetten als Wichtung bei Überlagerung.

Schritte bei Drehung daran orientieren,
   um wieviele Bildpunkte das Bild aus der Waagerechten gedreht wird.
   Um halbe Punkte zu drehen ist wahrscheinlich nicht sehr sinnvoll, oder?

besserer Matching-Score
   bei "Kaltes Herz" schlägt die Erkennung der optimalen relativen Verschiebung
      zwischen Teil links oben und rechts unten fehl
   Evtl. mit Wurzel der überlappenden Fläche wichten?

automatische Erkennung von fehlerhaften Paaren:
   Wenn bei Ausgleichsproblem großer Fehler bleibt,
   dann schaue, welche Paare man bei der Ausgleichsrechnung am besten weglässt.

bisher nur JPEG unterstützt
   JuicyPixel unterstützt auch TIFF und PNG
   aber wir müssten zusätzlich RGB u.ä. erlauben

Optionen:
   --output=PATH
   --output-hard=PATH
   --output-overlap
   --output-distancemap
   --quality=PERCENT
   --scale=FACTOR
   --smooth=RADIUS
   --minimum-overlap=SIZE
   --maximum-difference=REAL
   --pad-size=SIZE
   --verbose
   --help

   --angle fix rotation angle for the next input file

Abhängigkeit von gnuplot nicht nötig

unterschiedliche horizontale und vertikale Auflösung
   für diesen Fall könnte man allgemeine lineare Abbildung ansetzen

finetune-rotate:
   statt linearer Verteilung von kleinen Fenstern
      könnte man Zufallsverteilung nehmen

   wenn kleine Fenster nahezu konstante Werte enthalten,
      dann schlägt Algorithmus evtl. fehl
      Ich sollte vielleicht Fenster mit zu geringen Helligkeitsschwankungen ignorieren.

soll man "matching" besser nur auf innerem Rechteck mit vollständig gültigen Daten berechnen?
   Wie berechnet man (flächenmäßig) größtes einbeschriebenes Iso-Rechteck?

falsche Formatschablonen in Output-Dateinamen führen zu Laufzeitfehler
   Teste Format vorher auf richtiges Format :-)

Als Sahnehäubchen könnte Programm noch selber die richtige Orientierung
   in 90°-Schritten herausfinden.

Punkte auf dem Bildrand haben Abstand null
   das kann zu Division durch null führen
   Besser pauschal eins addieren?

Wie geht man mit 0/0 um?
   Tritt an allen Stellen auf, an denen kein Bildteil zu sehen ist.
   Anscheinend macht die GPU dort automatisch Null hin.
   Müsste auch auftreten, wenn man nur nicht überlappende Bilder hat
      "Ein einziges Bild" wäre davon ein Spezialfall.


kann man bei der schnellen Fourier-Transformation ausnutzen,
   wenn nur ein Teil der Daten ungleich null ist?

Algorithmus mal mit Ausschnitten von Bildern testen

man sieht bei mpb immer noch Schlitze an den Schnittstellen
   das dürfte eigentlich dank Rotationsmaske nicht sein.
   Ich muss mir mal Rotationsmasken ausgeben lassen und überprüfen.
   Hm, die Small-Bilder sind teilweise schon gedreht und haben helle Keile am Rand.
   Das erklärt alles.

man müsste eigentlich einen Rahmen mit 1 Bildpunkt Breite abschneiden,
   weil dieser Rand schon von der konstanten Randfortsetzung beeinträchtigt wird

Umsortieren in "Bitplanes":
   die Reihenfolge der Dimensionen sollte sein:
      Z :. Kanal :. Höhe :. Breite
   Dann kann man die gleiche Rotationsroutine
      für Graustufen und für Farbbilder verwenden.
   So lässt sich ein Bild aber schlecht mit einer Maske kombinieren.
   Vielleicht sollte ich doch einen eigenen YUV-Elementtyp definieren?
   Dann brauche auch aber auch Vektorskalierung und solche Sachen.


Annahme:
   alle Bilder nahezu in der selben Orientierung
      so ist sichergestellt,
         dass (leicht) verschiedene Auflösungen
         in x- und y-Richtung nicht stören
      180°-Grad-Drehungen kann man vorher rückgängig machen
   alle Bilder gleich groß

Zwei Phasen:
   Anordnung der Bilder finden
   Bilder überlagern


Orientierung finden, 1. Ansatz:
   Bild um maximal 1 Grad in 0.01-Grad-Schritten drehen
   Von jeder Drehung horizontales und vertikales Histogramm berechnen
   Nach dem Winkel suchen, wo im Histogramm die steilsten Flanken auftreten
      Solche Flanken sollten wenigstens vom Bildrand erzeugt werden,
      oder aber von Schrift.

Orientierung finden, 2. Ansatz:
   Für jeden Punkt über mehrere Ringe mitteln (Rotationsunabhängigkeit)
   Für jeden Punkt entsteht so ein Merkmalsvektor von vielleicht 5x3 Werten
   Diese Vektoren in ein quantisiertes Gitter eintragen.
   Ist in einer Zelle nur ein Vektor, so ist der Punkt besonders markant.
   Diese Punkte sollte man in anderen Bildern suchen.
   Hat man eine Menge Punkte in den Bildern einander zugeordnet,
      so kann man Drehung und Position herausfinden.

Orientierung finden, 3. Ansatz:
   Bild in kleinen Schritten drehen
   den Benutzer die passende Drehung aussuchen lassen
   oder schauen, wann es am besten zu anderem Bild passt

Position finden:
   Mit FFT zwei Bilder falten und Position mit höchster Korrelation nehmen

Überlagern:
   Es sollten Bilder linear interpoliert werden,
      so dass es keine harten Schnittstellen gibt.
   Die richtigen Wichtungsfaktoren für jedes Bild zu finden,
      ist ganz schön knifflig.
   Idee: Führe Aufgabe auf lineare Schnitte durch die Bilder zurück.
      Beobachtung:
         Intervalle, die andere Intervalle enthalten können wir weglassen.
         D.h. aber, dass es nur die Situation
            [          ]
              [          ]
                [          ]
         geben kann.
         Bei Schnitten durch Bilder können auf einzelnen Geraden
         durchaus Intervalle komplett in anderen enthalten sein,
         und man muss die Teilintervalle trotzdem beachten.
         D.h. dass man die 2D-Aufgabe nicht auf 1D zurückführen kann,
         und weil die Anordnung nichttrivialer Intervalle
         immer die gleiche ist, lässt sich aus dem 1D-Fall auch nichts lernen.
